{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dc0175-b2ca-4c23-92a5-19f30bbc975b",
   "metadata": {},
   "source": [
    "# MLOps exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a76de-8b93-465e-86af-0c2a8e9ea02e",
   "metadata": {},
   "source": [
    "## Execise 1\n",
    "\n",
    "In this exercise, do the following:\n",
    "1. Create a function that preprocess new ames data in the same way as the original ames data was preprocessed in step 5 in the `MLOps.ipynb` notebook.\n",
    "2. Create a function that takes as input a new ames dataset and a model. The function should pre-process the new data and evaluate the model on that new data using mean absolute error.\n",
    "3. Test the function from 2. on the \"NewAmesData1.csv\" dataset and the best model from the `MLOps.ipynb` notebook.\n",
    "4. Test the function from 2. on the \"NewAmesData2.csv\" dataset and the best model from the `MLOps.ipynb` notebook. Do you see any drift?\n",
    "5. Do you see a data drift in \"NewAmesData2.csv\"? If so, for which variables?\n",
    "6. Do you see a data drift in \"NewAmesData4.csv\"? If so, for which variables?\n",
    "7. Create a function that retrain a model on the new data as well as the old training data\n",
    "8. Retrain the `model_final` on the new data \"NewAmesData1.csv\" as well as the old training data, using the function from 5. Then test the new model on the old testset.\n",
    "9. Split the \"NewAmesData2.csv\" dataset into a train and test set. Train  the best model from the `MLOps.ipynb` notebook on the training part and test it on the test part. Did you get a better model? Now combine your new training data with the original training data and retrain the model on that. Did that give you a better model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff1308",
   "metadata": {},
   "source": [
    "1. Create a function that preprocess new ames data in the same way as the original ames data was preprocessed in step 5 in the `MLOps.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44f85f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import  mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6ac6a31-ec39-4d31-aa94-4c8ef9f0d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames = pd.read_csv(\"data\\\\AmesHousing.csv\")\n",
    "ames1 = pd.read_csv(\"data\\\\NewAmesData1.csv\")\n",
    "ames2 = pd.read_csv(\"data\\\\NewAmesData2.csv\")\n",
    "ames4 = pd.read_csv(\"data\\\\NewAmesData4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f08b5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df):\n",
    "#    df = df[df[\"Lot Area\"] <= 75000]\n",
    "    actual = df[['SalePrice']]\n",
    "    df = df[[\"Lot Area\", \"Overall Cond\", \"Year Built\", \"Gr Liv Area\", \"TotRms AbvGrd\", \"Mo Sold\", \"Yr Sold\", \"Bldg Type\", \"Neighborhood\"]]\n",
    "    df = df.join(pd.get_dummies(df[\"Bldg Type\"], drop_first=True, dtype = \"int\", prefix=\"BType\"))\n",
    "    df = df.join(pd.get_dummies(df[\"Neighborhood\"], drop_first=True, dtype = \"int\", prefix=\"Nbh\"))\n",
    "    df = df.drop(columns = [\"Bldg Type\", \"Neighborhood\"])\n",
    "    return df, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def run(df, modelpath, actual):\n",
    "    with open(modelpath, \"rb\") as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    predictions = loaded_model.predict(df)\n",
    "    return predictions, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b96ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "19318.837034992688\n",
      "Model loaded successfully!\n",
      "122803.13811326215\n"
     ]
    }
   ],
   "source": [
    "pp_ames1, actual_ames1= preproc(ames1)\n",
    "\n",
    "pp_ames2, actual_ames2= preproc(ames2)\n",
    "\n",
    "ames1_pred, act= run(pp_ames1, \"C:\\\\Users\\\\Hassan\\\\Desktop\\\\Data and Things\\\\code\\\\DAT_Notebooks_&_data\\\\lec_12\\\\mlruns\\\\0\\\\88dd1a7db9104fb0bacd6f529544a008\\\\artifacts\\\\model_rf_500\\\\model.pkl\", actual_ames1)\n",
    "print(mean_absolute_error(act, ames1_pred))\n",
    "\n",
    "ames2_pred, act= run(pp_ames2, \"C:\\\\Users\\\\Hassan\\\\Desktop\\\\Data and Things\\\\code\\\\DAT_Notebooks_&_data\\\\lec_12\\\\mlruns\\\\0\\\\88dd1a7db9104fb0bacd6f529544a008\\\\artifacts\\\\model_rf_500\\\\model.pkl\", actual_ames2)\n",
    "print(mean_absolute_error(act, ames2_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
